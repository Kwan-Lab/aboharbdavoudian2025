{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region Selector Script\n",
    "- Retrieves featureDicts generated during classifySamples analyses\n",
    "- Retrieves lightsheet data\n",
    "- For each included region returned in the contrast, Show means across regions for each element + saline\n",
    "- Sort the table of regions based on greatest relative difference b/t regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lightSheet(lightsheet_data, regionList, drug, salineScale, acaNorm):\n",
    "    # Use the class to extract data from lightsheetData\n",
    "    ls_data_comp = lightsheet_data.copy()\n",
    "    classifyDict = dict(label = f\"class_{drug}\") \n",
    "\n",
    "    conv_dict = hf.create_drugClass_dict(classifyDict)\n",
    "    conv_dict['SAL'] = 'Saline'\n",
    "\n",
    "    ls_data_comp[classifyDict['label']] = ls_data_comp['drug'].map(conv_dict)\n",
    "    ls_data_comp = ls_data_comp.dropna(subset=[classifyDict['label']])\n",
    "\n",
    "    # If scaling by ACA\n",
    "    if acaNorm:\n",
    "        ls_data_sums = ls_data_comp.groupby(['abbreviation', \"dataset\"])['count'].sum().reset_index()\n",
    "        ls_data_sums_ACA = ls_data_sums[ls_data_sums.abbreviation.isin(['ACAv'])]\n",
    "        ls_data_sums_ACA = ls_data_sums_ACA.groupby(['dataset'])['count'].sum()\n",
    "\n",
    "        # Scaling factor of ACAv in mouse * mean ACAv count in all treated mice.\n",
    "        ACA_drug = ls_data_sums_ACA[~ls_data_sums_ACA.index.str.contains('SAL')]\n",
    "        ACA_drug_mean = ACA_drug.mean()\n",
    "\n",
    "        for dSet in ACA_drug.index:\n",
    "            # in each dataset, scale the entire dataset to the mean.\n",
    "            ls_data_comp.loc[ls_data_comp['dataset'] == dSet, 'count'] = ls_data_comp.loc[ls_data_comp['dataset'] == dSet, 'count'] * ACA_drug_mean/ACA_drug[dSet]\n",
    "\n",
    "    # Filter the table based on regions of interest\n",
    "    ls_data_comp_z = ls_data_comp.groupby(['abbreviation', f\"class_{drug}\"])['count'].mean().reset_index()\n",
    "    ls_data_comp_piv = ls_data_comp_z.pivot(index='abbreviation', columns=f\"class_{drug}\", values='count')\n",
    "    ls_data_comp_regions = ls_data_comp_piv.loc[ls_data_comp_piv.index.isin(regionList), :]\n",
    "\n",
    "    # Scale columns by by Saline\n",
    "    fmtStr = '.0f'\n",
    "\n",
    "    if salineScale:\n",
    "        lsdc_piv_datas = ls_data_comp_regions.values\n",
    "        class_names = list(ls_data_comp_regions.columns)\n",
    "        sal_idx = [x == 'Saline' for x in class_names]\n",
    "        other_idx = [not elem for elem in sal_idx]\n",
    "\n",
    "        remaining_classes = list(compress(class_names, other_idx))\n",
    "        remaining_data_salScale = (lsdc_piv_datas[:, other_idx] - lsdc_piv_datas[:, sal_idx])/lsdc_piv_datas[:, sal_idx]\n",
    "        lsdc_piv_scaled = pd.DataFrame(remaining_data_salScale, index=ls_data_comp_regions.index, columns=remaining_classes)\n",
    "        lsdc_plot = lsdc_piv_scaled\n",
    "        fmtStr = '.0%'\n",
    "\n",
    "    else: \n",
    "        lsdc_plot = ls_data_comp_regions\n",
    "\n",
    "    # Sort the table\n",
    "    lsdc_plot = lsdc_plot.copy()\n",
    "    lsdc_plot['Diff'] = lsdc_plot.iloc[:, 0] - lsdc_plot.iloc[:, 1]\n",
    "    lsdc_plot = lsdc_plot.sort_values('Diff')\n",
    "    hvAxBool = list(lsdc_plot['Diff'] > 0)\n",
    "    if any(hvAxBool):\n",
    "        hvAxIdx = hvAxBool.index(True)\n",
    "    else:\n",
    "        hvAxIdx = 0\n",
    "\n",
    "    return lsdc_plot, fmtStr, hvAxIdx\n",
    "\n",
    "def find_feature_dict_files(root_dir, tags):\n",
    "    feature_dict_files = []\n",
    "\n",
    "    # Traverse the directory structure\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            # Check if the file is named 'featureDict.pkl'\n",
    "            if filename == 'scoreDict_Real.pkl':\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "\n",
    "                # Check if the file contains all specified substrings in the 'tags' list\n",
    "                if all(tag in file_path for tag in tags):\n",
    "                    feature_dict_files.append(file_path)\n",
    "\n",
    "    return feature_dict_files\n",
    "\n",
    "def extract_substrings_between_a_and_b(string_list, a, b):\n",
    "    extracted_substrings = []\n",
    "\n",
    "    for input_string in string_list:\n",
    "        # Define the regular expression pattern to match substrings between A and B\n",
    "        pattern = re.compile(f'{re.escape(a)}(.*?){re.escape(b)}', re.DOTALL)\n",
    "        \n",
    "        # Find all matches in the input string\n",
    "        matches = pattern.findall(input_string)\n",
    "\n",
    "        # Append the matched substrings to the result list\n",
    "        extracted_substrings.extend(matches)\n",
    "\n",
    "    return extracted_substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve featureDicts\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, re, sys\n",
    "from collections import Counter\n",
    "sys.path.append('..//../functionScripts/')\n",
    "import helperFunctions as hf\n",
    "\n",
    "# Load lightsheetData\n",
    "lightsheet_data = pd.read_pickle(r\"C:\\\\OneDrive\\\\KwanLab\\\\Lightsheet_cFos_Pipeline\\\\figureScripts\\\\lightsheet_data.pkl\")\n",
    "\n",
    "filtList = True\n",
    "filtThresh = 75\n",
    "salineScale = False\n",
    "acaNorm = False\n",
    "plotData = False\n",
    "\n",
    "# Example usage:\n",
    "root_directory = \"C:\\OneDrive\\KwanLab\\Lightsheet_cFos_Pipeline\\\\1.scaled_Output\\classif\\\\\"\n",
    "tags_to_match = ['data=count_norm', 'PowerTrans_RobScal_fSel_BorFS']\n",
    "\n",
    "matching_files = find_feature_dict_files(root_directory, tags_to_match)\n",
    "drugList = extract_substrings_between_a_and_b(matching_files, 'count_norm-', '\\PowerTrans')\n",
    "\n",
    "for drug, dictPath in zip(drugList, matching_files):\n",
    "\n",
    "    # Retrieve both the relevant dictionaries\n",
    "    allRegion, allCount = [], []\n",
    "\n",
    "    with open(dictPath, 'rb') as f:                 \n",
    "        scoreDict = pkl.load(f)\n",
    "    \n",
    "    # Extract relevant values\n",
    "    pltTitle = scoreDict['compLabel'].replace(' ', '_')\n",
    "    pltTitle = scoreDict['compLabel'].replace('/', '+')\n",
    "    regionList = np.concatenate(scoreDict['featuresPerModel'])\n",
    "    regionDict = dict(Counter(regionList))\n",
    "\n",
    "    regionList = np.array(list(regionDict.keys()))\n",
    "    featureCount = np.array(list(regionDict.values()))\n",
    "    \n",
    "    if filtList:\n",
    "        keepInd = (featureCount >= filtThresh)\n",
    "        regionList = regionList[keepInd]\n",
    "        featureCount = featureCount[keepInd]\n",
    "    \n",
    "    allRegion.append(regionList)\n",
    "    allCount.append(featureCount)\n",
    "    \n",
    "    # Use the class to extract data from lightsheetData\n",
    "    lsdc_plot, fmtStr, hvAxIdx = process_lightSheet(lightsheet_data, regionList, drug, salineScale, acaNorm)\n",
    "    \n",
    "    # Save this for importing into brainrender (which has to run older versions of python/packages)\n",
    "    fullSavePath = f'{os.getcwd()}\\\\br_{pltTitle}.csv'\n",
    "    lsdc_plot.to_csv(fullSavePath)\n",
    "\n",
    "    if plotData:\n",
    "        # Keep only first two columns\n",
    "        if salineScale:\n",
    "            lsdc_plot = lsdc_plot.iloc[:, 0:2]\n",
    "        else:\n",
    "            lsdc_plot = lsdc_plot.iloc[:, 0:3]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(1.5 * len(lsdc_plot.columns), .6 * len(lsdc_plot.index)))\n",
    "        \n",
    "        sns.heatmap(lsdc_plot, annot=True, fmt=fmtStr)  #, cmap='RdBu', center=0, vmin=-1, vmax=1, annot=True, fmt=fmtStr\n",
    "        titleStr = f\"{pltTitle}\"\n",
    "\n",
    "        if acaNorm:\n",
    "            titleStr += ' ACA norm'\n",
    "\n",
    "        if salineScale:\n",
    "            titleStr += ' (% Change vs Saline)'\n",
    "\n",
    "        # Draw a line for the 0 cross point\n",
    "        plt.axhline(y=hvAxIdx, color='white', linewidth=2)\n",
    "\n",
    "        plt.ylabel(\"Region Abbv.\")\n",
    "        plt.xlabel(\"Treatment\", fontsize=12)\n",
    "        plt.tick_params(axis='x', which='both', length=0)\n",
    "        plt.title(titleStr, fontsize=10)\n",
    "        plt.yticks(rotation=0)\n",
    "\n",
    "        # plt.savefig(dirDict['classifyDir'] + titleStr + '.png', dpi=300, format='png', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cFosV1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

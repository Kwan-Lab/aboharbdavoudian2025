{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'scoreDict.pkl' files in directories containing ['data=count_norm-', 'PowerTrans_RobScal_fSel_BorFS_clf_LogReg(multinom)_CV100']:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import os, sys, random\n",
    "import pickle as pkl\n",
    "from os.path import exists, join\n",
    "\n",
    "sys.path.append('../dependencies/')\n",
    "\n",
    "# Figure dir\n",
    "figDir = os.path.join(os.getcwd(), 'figures_output')\n",
    "if not os.path.isdir(figDir):\n",
    "    os.makedirs(figDir)\n",
    "\n",
    "# Define the target directory\n",
    "targDir = \"C:\\OneDrive\\KwanLab\\Lightsheet_cFos_Pipeline\\\\1.scaled_Output\\\\classif\"\n",
    "\n",
    "# Define a list of substrings to filter directories\n",
    "tagList = ['data=count_norm-', 'PowerTrans_RobScal_fSel_BorFS_clf_LogReg(multinom)_CV100']\n",
    "\n",
    "# Call the function and get the list of paths based on the tagList\n",
    "score_dict_paths = []\n",
    "\n",
    "# Walk through the directory and its subdirectories\n",
    "for root, dirs, files in os.walk(targDir):\n",
    "    # Check if 'scoreDict.pkl' is present in the files\n",
    "    if 'scoreDict_Real.pkl' in files:\n",
    "        if all(tag in root for tag in tagList):\n",
    "            score_dict_paths.append(os.path.join(root, 'scoreDict_Real.pkl'))\n",
    "\n",
    "# Each directory name will be used to generate a label, based on the sequence between the strings in the directory name below\n",
    "startStr = 'count_norm-'\n",
    "endStr = '\\PowerTrans'\n",
    "featureLists, countNames  = [], []\n",
    "\n",
    "# Print the result\n",
    "print(f\"Found 'scoreDict.pkl' files in directories containing {tagList}:\")\n",
    "for path in score_dict_paths:\n",
    "\n",
    "    # Load the scoreDict.pkl file and extract desired variables.\n",
    "    with open(path, 'rb') as f:                 \n",
    "        featureDict = pkl.load(f)\n",
    "        featureLists.append(featureDict['featuresPerModel'])\n",
    "\n",
    "    # Extract the label for the entry\n",
    "    countNames.append(featureDict['compLabel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Violin Plot for Feature counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Style of Font\n",
    "# Set font to 12 pt Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'6-F-DET vs PSI' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mlen\u001b[39m(sublist) \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m inner_list] \u001b[38;5;28;01mfor\u001b[39;00m inner_list \u001b[38;5;129;01min\u001b[39;00m featureLists]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Use numpy.argsort to obtain the indices that would sort the original list\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m sort_indices \u001b[38;5;241m=\u001b[39m [scoreNames\u001b[38;5;241m.\u001b[39mindex(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m origNames]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Use the sorted indices to reorder the original list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scoreNames)[sort_indices]\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mlen\u001b[39m(sublist) \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m inner_list] \u001b[38;5;28;01mfor\u001b[39;00m inner_list \u001b[38;5;129;01min\u001b[39;00m featureLists]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Use numpy.argsort to obtain the indices that would sort the original list\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m sort_indices \u001b[38;5;241m=\u001b[39m [\u001b[43mscoreNames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m origNames]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Use the sorted indices to reorder the original list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scoreNames)[sort_indices]\n",
      "\u001b[1;31mValueError\u001b[0m: '6-F-DET vs PSI' is not in list"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "colorsList = [[82, 211, 216], [56, 135, 190]]\n",
    "colorsList = np.array(colorsList)/256\n",
    "\n",
    "origNames = ['5MEO vs PSI', 'MDMA vs PSI', 'A-SSRI vs PSI', 'KET vs PSI', '6-F-DET vs PSI', '5MEO vs 6-F-DET', 'A-SSRI vs C-SSRI', 'MDMA vs PSI/5MEO', '6-F-DET vs PSI/5MEO']\n",
    "scoreNames = countNames\n",
    "\n",
    "# Your list of lists (sublists with numbers)\n",
    "data = [[len(sublist) for sublist in inner_list] for inner_list in featureLists]\n",
    "\n",
    "# Use numpy.argsort to obtain the indices that would sort the original list\n",
    "sort_indices = [scoreNames.index(name) for name in origNames]\n",
    "\n",
    "# Use the sorted indices to reorder the original list\n",
    "names = np.array(scoreNames)[sort_indices]\n",
    "data = np.array(data)[sort_indices]\n",
    "\n",
    "# If swapping names is desired\n",
    "# swapDict = dict()\n",
    "# swapDict['MDMA vs PSI/5MEO'] = 'PSI/5MEO vs MDMA'\n",
    "# swapDict['6-F-DET vs PSI/5MEO'] = 'PSI/5MEO vs 6-F-DET'\n",
    "\n",
    "# for i in range(len(names)):\n",
    "#     if names[i] in swapDict:\n",
    "#         names[i] = swapDict[names[i]]\n",
    "\n",
    "# Create a data frame with melted data\n",
    "flat_data = [item for sublist in data for item in sublist]\n",
    "\n",
    "df = pd.melt(pd.DataFrame(data, index=names).T, var_name='Category', value_name='Values')\n",
    "\n",
    "# Create horizontally oriented violin plot\n",
    "plt.figure(figsize=(5, 5))  # Adjust the width and height as needed\n",
    "\n",
    "ax = sns.violinplot(x='Values', y='Category', bw_adjust=.5, data=df, orient='h', color=colorsList[0])  #, palette=colors)  # Remove inner bars and set color\n",
    "# for violin in ax.collections:\n",
    "#     violin.set_alpha(1)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Number of Regions in Classifier')\n",
    "plt.ylabel('Classifier')\n",
    "\n",
    "plt.savefig(f\"{figDir}\\\\RegionCountPerSplit_violin.svg\", format='svg', bbox_inches='tight')     \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Distance matricies to compare features across comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions\n",
    "from collections import Counter\n",
    "\n",
    "def listToCounterFilt(listArray, filterByFreq=0):\n",
    "\n",
    "    counter_u = Counter(listArray)\n",
    "    \n",
    "    if filterByFreq > 0:\n",
    "        return Counter({k: v for k, v in counter_u.items() if v >= filterByFreq})\n",
    "    else:\n",
    "        return counter_u\n",
    "\n",
    "def overlapCounter(list1, list2, filterByFreq=0):\n",
    "\n",
    "    counter_u = listToCounterFilt(list1, filterByFreq)\n",
    "    counter_v = listToCounterFilt(list2, filterByFreq)\n",
    "\n",
    "    list1 = list(counter_u.keys())\n",
    "    list2 = list(counter_v.keys())\n",
    "\n",
    "    only_list1 = list(set(list1) - set(list2))\n",
    "    only_list2 = list(set(list2) - set(list1))\n",
    "\n",
    "    intersection = list(set(list1) & set(list2))\n",
    "    \n",
    "    return only_list1, only_list2, intersection\n",
    "\n",
    "def weighted_jaccard_similarity(u, v, filt):\n",
    "\n",
    "    counter_u, counter_v = Counter(u), Counter(v)\n",
    "\n",
    "    # If Filt is non-0, filter out features in each counter whose count is not above it.\n",
    "    if filt:\n",
    "        counter_u = Counter({k: v for k, v in counter_u.items() if v > filt})\n",
    "        counter_v = Counter({k: v for k, v in counter_v.items() if v > filt})\n",
    "\n",
    "    intersection = sum((counter_u & counter_v).values())\n",
    "    union = sum((counter_u | counter_v).values())\n",
    "\n",
    "    # Using the modified Jaccard similarity with frequency\n",
    "    similarity = intersection / union if union != 0 else 0\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterByFreq = 75\n",
    "\n",
    "modelCount = len(featureLists)\n",
    "# regionDict = dict(Counter(featureLists[0]))\n",
    "# labels, counts = list(regionDict.keys()), list(regionDict.values())\n",
    "\n",
    "# Initialize a grid\n",
    "grid = [[0 for _ in range(modelCount)] for _ in range(modelCount)]\n",
    "\n",
    "# Flatten every list\n",
    "featureListFlat = [[element for item in subList for element in item] for subList in featureLists]\n",
    "\n",
    "jacSim = False \n",
    "\n",
    "# compare the mean distances across items of the list\n",
    "for idx_a, listA in enumerate(featureListFlat):\n",
    "    for idx_b, listB in enumerate(featureListFlat):\n",
    "        \n",
    "        if jacSim:\n",
    "            # Jaccard Sim\n",
    "            grid[idx_a][idx_b] = weighted_jaccard_similarity(listA, listB, 75)\n",
    "        else:\n",
    "            # Overlap count\n",
    "            _, _, intersection = overlapCounter(listA, listB, filterByFreq)\n",
    "            grid[idx_a][idx_b] = len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "# Set the title\n",
    "if jacSim:\n",
    "    titleStr = f'% Similarity Between Feature Lists at (>={filterByFreq})'\n",
    "else:\n",
    "    titleStr = f'Overlap Count Between Feature Lists at (>={filterByFreq})'\n",
    "\n",
    "# Plot the grid\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "im = sns.heatmap(grid, cmap='Blues', annot=True, fmt='.0f', ax=ax, yticklabels=scoreNames, xticklabels=scoreNames, annot_kws={'size': 15})\n",
    "\n",
    "# Remove the colorbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.remove()\n",
    "\n",
    "# Set font size for x-axis ticks and labels\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "\n",
    "# Set font size for y-axis ticks and labels\n",
    "ax.tick_params(axis='y', labelsize=12, rotation=0)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "# Cycle through sns heatmap annotations and remove those that are equal to 0\n",
    "for text in ax.texts:\n",
    "    if int(text.get_text()) == 0:\n",
    "        text.set_text(\"\")\n",
    "\n",
    "# plt.title(titleStr, fontdict={'fontsize': 18})\n",
    "plt.savefig(f\"{figDir}\\\\MeanSimilarity_heatmap.svg\", format='svg', bbox_inches='tight')     \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import textwrap\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=12, break_on_hyphens=False)  # Adjust width as needed\n",
    "\n",
    "# Sample data\n",
    "if 0:\n",
    "    for idx1, list1 in enumerate(featureListFlat):\n",
    "        for idx2, list2 in enumerate(featureListFlat):\n",
    "\n",
    "            # Skip the same list\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    "\n",
    "            # Filter out features in each counter whose count is not above it.\n",
    "            only_list1, only_list2, intersection = overlapCounter(list1, list2, filterByFreq)\n",
    "\n",
    "            # Skip if there is no overlap\n",
    "            if intersection == []:\n",
    "                continue\n",
    "\n",
    "            # Create a Venn diagram\n",
    "            venn_diagram = venn2(subsets=(len(only_list1), len(only_list2), len(intersection)/2),\n",
    "                                set_labels=(scoreNames[idx1], scoreNames[idx2]))\n",
    "\n",
    "\n",
    "            venn_labels = {'100': only_list1, '010': only_list2, '110': intersection}\n",
    "            for idx, (labId, labels) in enumerate(venn_labels.items()):\n",
    "                wrapped_labels = wrapper.fill(text='  '.join(labels))\n",
    "                venn_diagram.get_label_by_id(labId).set_text(wrapped_labels)\n",
    "                venn_diagram.get_label_by_id(labId).set_fontsize(8)  # Adjust font size if needed\n",
    "\n",
    "            # # Customize the size of the Venn diagram\n",
    "            # plt.gcf().set_size_inches(8, 8)\n",
    "            figName = f'VD_{scoreNames[idx1]} and {scoreNames[idx2]}'\n",
    "            figName = figName.replace('/', '+')\n",
    "            figName = figName.replace(' ', '_')\n",
    "            plt.savefig(f\"{figDir}\\\\{figName}.svg\", format='svg', bbox_inches='tight')     \n",
    "\n",
    "            # Display the plot\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the single heatmap of features above the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Mode: Create plot with colorbar, then without, and grab the svg item and place it in the second plot to ensure even spacing\n",
    "# Creates the heatmap for the data\n",
    "\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 9\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import matplotlib.ticker as tkr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../dependencies/')\n",
    "sys.path.append('../functionScripts/')\n",
    "sys.path.append('../testScripts/')\n",
    "\n",
    "import helperFunctions as hf\n",
    "import plotFunctions as pf\n",
    "\n",
    "# Load the lightsheet_data.pkl from the testScripts folder into a pandas df\n",
    "df_raw = pd.read_pickle('../testScripts/lightsheet_data.pkl')\n",
    "\n",
    "# Create a sorted structure from the data for scaffolding the desired heatmap\n",
    "brainAreaColorDict = hf.create_color_dict(dictType='brainArea', rgbSwitch=0)\n",
    "brainAreaPlotDict = hf.create_brainArea_dict('short')\n",
    "regionArea = hf.create_region_to_area_dict(df_raw, 'abbreviation')\n",
    "regionArea['Region_Color'] = regionArea['Brain_Area'].map(brainAreaColorDict)\n",
    "\n",
    "df_Tilted = df_raw.pivot(index='abbreviation', columns='dataset', values='count')\n",
    "df_Tilted = df_Tilted.reindex(regionArea['abbreviation'].tolist(), axis=0)\n",
    "\n",
    "# Set variables\n",
    "dataFeature = 'abbreviation'\n",
    "blockCount = 2\n",
    "# filterByFreq = 75 # Set Above\n",
    "\n",
    "# Process the data from above\n",
    "featureListDicts = [listToCounterFilt(x, filterByFreq=0) for x in featureListFlat]\n",
    "featureListArray = [list(x.keys()) for x in featureListDicts]\n",
    "\n",
    "# Add in columns for each of the actual comparisons.\n",
    "df_frame = df_Tilted.reindex(columns=scoreNames)\n",
    "\n",
    "# Populate df_frame with 0s\n",
    "for col in df_frame.columns:\n",
    "    df_frame[col] = 0\n",
    "    \n",
    "for idx, (comp, featureList) in enumerate(zip(df_frame.columns, featureListDicts)):\n",
    "    for regionName in featureList.keys():\n",
    "        df_frame.loc[regionName, comp] = featureList[regionName]\n",
    "    # df_frame[comp] = df_frame.index.isin(featureListArray[idx])\n",
    "    # print(f\"{comp}: {df_frame[comp].sum()}\")\n",
    "        \n",
    "# Remove any rows which are not above threshold\n",
    "df_plot = df_frame[df_frame.sum(axis=1) > 74]\n",
    "    \n",
    "# Remove the abbreviations from regionArea not represented in df_plot, Filter the regionArea for 'Cortex' and 'Thalamus'\n",
    "regionArea = hf.create_region_to_area_dict(df_raw, dataFeature)\n",
    "regionArea = regionArea[regionArea['abbreviation'].isin(df_plot.index)]\n",
    "regionArea = regionArea[regionArea['Brain_Area'].isin(['Cortex', 'Thalamus'])]\n",
    "\n",
    "# Sort the data to be combined per larger area\n",
    "df_plot = df_plot.loc[regionArea[dataFeature]]\n",
    "modelCount = len(df_plot.columns)\n",
    "\n",
    "# Create indicies for dividing the data into the correct number of sections regardless of the size\n",
    "row_idx_set = np.zeros((blockCount, 2), dtype=int)\n",
    "indices = np.linspace(0, len(df_plot), num=blockCount+1, dtype=int)\n",
    "for block_idx in range(blockCount):\n",
    "    row_idx_set[block_idx][0] = indices[block_idx]\n",
    "    row_idx_set[block_idx][1] = indices[block_idx+1]\n",
    "\n",
    "# Hand change to make Cortex 1st block, Thal 2nd\n",
    "row_idx_set[0,1] = 25\n",
    "row_idx_set[1,0] = 25\n",
    "\n",
    "# merge df_plot and regionArea, moving the Brain_Area_Idx and Brain_Area columns to df_plot\n",
    "df_plot_combo = df_plot.merge(regionArea, left_index=True, right_on=dataFeature)\n",
    "\n",
    "# Cycle through the df_plot_combo's distinct Brain_Area_Idx, and resort data by row sums\n",
    "newIdx = []\n",
    "for idx in regionArea.Brain_Area_Idx.unique():\n",
    "    # Identify which regions have the same Brain_Area_Idx\n",
    "    df_seg = df_plot_combo[df_plot_combo.Brain_Area_Idx == idx]\n",
    "    sorted_seg_idx = df_seg.iloc[:, 0:modelCount].sum(axis=1).sort_values(ascending=False).index\n",
    "\n",
    "    # Append to list\n",
    "    newIdx = newIdx + list(sorted_seg_idx)\n",
    "\n",
    "# Resort the data\n",
    "df_plot = df_plot_combo.reindex(newIdx, axis=0)\n",
    "df_plot = df_plot.set_index('abbreviation')\n",
    "df_plot = df_plot.drop(columns=['Brain_Area_Idx', 'Brain_Area'])\n",
    "\n",
    "# Resort the columns to match 'origNames'\n",
    "df_plot = df_plot[origNames]\n",
    "\n",
    "# Drop the columns which do not include the string 'PSI'\n",
    "df_plot = df_plot.loc[:, df_plot.columns.str.contains('PSI')]\n",
    "\n",
    "# Update the column names to have 'PSI' in front.\n",
    "origcolNames = df_plot.columns\n",
    "colNames = [x.split(' vs ') for x in df_plot.columns]\n",
    "newColNames = [f'{x[1]} vs {x[0]}' for x in colNames]\n",
    "newColNames[-1], newColNames[-2] = origcolNames[-1], origcolNames[-2]\n",
    "newColNames = [x.replace('/', ' & ') for x in newColNames]\n",
    "df_plot.columns = newColNames\n",
    "\n",
    "# Plotting variables\n",
    "formatter = tkr.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(False)\n",
    "formatter.set_powerlimits((-2, 2))\n",
    "\n",
    "scalefactor = 12\n",
    "figH = (scalefactor*2.5)/blockCount\n",
    "figW = blockCount * 2.5\n",
    "\n",
    "colorbar = [False, True]\n",
    "\n",
    "for cbs in colorbar:\n",
    "\n",
    "    fig, axes = plt.subplots(1, blockCount, figsize=(figW, figH))  # Adjust figsize as needed\n",
    "    # figsize=(scalefactor*2.4, len(df_plot)/len(row_idx_set) * scalefactor * 0.0125)\n",
    "\n",
    "    if blockCount == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, row_set in enumerate(row_idx_set):\n",
    "\n",
    "        # Slice and modify previous structures to create segment\n",
    "        df_plot_seg = df_plot.iloc[row_set[0]: row_set[1], :]\n",
    "        regionArea_local = regionArea[regionArea[dataFeature].isin(df_plot_seg.index)]\n",
    "        region_idx = regionArea_local.Brain_Area_Idx  # Extract for horizontal lines in plot later.\n",
    "\n",
    "        matrix = df_plot_seg.values\n",
    "\n",
    "        xticklabels = df_plot_seg.columns.values.tolist()\n",
    "        yticklabels = df_plot_seg.index.values.tolist()\n",
    "\n",
    "        heatmap = sns.heatmap(matrix, cmap='crest', ax=axes[idx] , fmt='.2f', cbar = False, square=True, yticklabels=yticklabels, xticklabels=xticklabels, cbar_kws={\"format\": formatter}, center=0)\n",
    "        horzLineColor = 'black'\n",
    "\n",
    "        # Rotate the xticklabels 45 degrees\n",
    "        axes[idx].set_xticklabels(axes[idx].get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "        # Add a colorbar\n",
    "        # Change the colorbar labels to be in non-scientific notation\n",
    "\n",
    "        if cbs:\n",
    "            cbar = heatmap.figure.colorbar(heatmap.collections[0], ax=axes[idx], location='right', use_gridspec=True, pad=0.05)\n",
    "            cbar.set_label('Feature Count', rotation=270, labelpad=5)\n",
    "            cbar.ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Add in horizontal lines breaking up brain regions types.\n",
    "        line_break_num, line_break_ind = np.unique(region_idx, return_index=True)\n",
    "        for l_idx in line_break_ind[1:]:\n",
    "            axes[idx].axhline(y=l_idx, color=horzLineColor, linewidth=1)\n",
    "            \n",
    "        # Set the yl abel on the first subplot.\n",
    "        # if idx == 0:\n",
    "        #     axes[idx].set_ylabel(\"Region Names\", fontsize=20)\n",
    "\n",
    "        # if idx == 2:\n",
    "        #     cbar = heatmap.collections[0].colorbar\n",
    "        #     cbar.set_label('Colorbar Label', rotation=270, labelpad=5)\n",
    "\n",
    "    titleStr = f\"FeatureCountHeatmap\"  \n",
    "    # fig.suptitle(titleStr, fontsize=20, y=1)\n",
    "    # fig.text(0.5, -.02, \"Samples Per Group\", ha='center', fontsize=20)\n",
    "    plt.tight_layout(h_pad = 0, w_pad = .5)\n",
    "\n",
    "    plt.savefig(f\"{titleStr}_cb_{cbs}.svg\", dpi=300, format='svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cFosProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

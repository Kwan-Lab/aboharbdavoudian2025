{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test script for classification\n",
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Good idea to add this folder to the json.settings file as \"python.analysis.extraPaths\".\n",
    "sys.path.append('../functionScripts/')\n",
    "\n",
    "import plotFunctions # totalCountsPlot, data_heatmap, correlation_plot\n",
    "import analysisFunctions\n",
    "import initFunctions as initf #import createDirs, debugReport, loadLightSheetData\n",
    "import classifyFunctions\n",
    "import helperFunctions\n",
    "\n",
    "importlib.reload(initf)\n",
    "\n",
    "# Set Paths to data and output\n",
    "dirDict = dict()\n",
    "rootDir = 'C:\\OneDrive\\KwanLab\\Lightsheet_cFos_Pipeline\\\\'\n",
    "dirDict['atlasDir'] = rootDir + 'Atlas\\\\'\n",
    "dirDict['dataDir'] = rootDir + 'Data\\\\'\n",
    "dirDict['B1'] =       dirDict['dataDir'] + 'lightSheetV1\\\\'\n",
    "dirDict['B2'] =       dirDict['dataDir'] + 'lightSheetV2Rev\\\\'   #3/6/23 - Looking at the new, Realigned batch 2 data. #Realigned\n",
    "dirDict['B2_Orig'] =  dirDict['dataDir'] + 'lightSheetV2\\\\'\n",
    "dirDict['B3'] =       dirDict['dataDir'] + 'lightSheetV3\\\\'      #3/6/23 - Batch 3 with MDMA\n",
    "dirDict['outputFormat'] = 'svg'\n",
    "\n",
    "batchSplit = False          # Splits drugs from the first batch of data, from the second, from the 3rd. Batch 1 is labeled with 'a' (aSAL, aKET, aPSI), Batch 3 (cKET, MDMA)\n",
    "splitTag  = ['a', '', 'c']  # Appended the to beginning of data from the first batch (PSI, KET, SAL -> aPSI, KET, aSAL).\n",
    "testSplit = False           # Splits an individual drug for the sake of examining self-similarity\n",
    "oldBatch2 = False\n",
    "\n",
    "debugOutputs = False        # Saves csvs at intervals\n",
    "scalingFactor = True        # Applies 1/total_cells as a scaling factor per mouse.\n",
    "debug_ROI = ['Dorsal nucleus raphe']\n",
    "outputFormat = 'png'\n",
    "\n",
    "switchDir = dict(testSplit=testSplit, batchSplit=batchSplit, splitTag=splitTag, oldBatch2=oldBatch2, debugOutputs=debugOutputs, scalingFactor=scalingFactor, debug_ROI=debug_ROI, outputFormat=outputFormat)\n",
    "\n",
    "# Make directories, and add their strings to the directory dictionary.\n",
    "dirDict = initf.createDirs(rootDir, switchDir, dirDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Figure style\n",
    "# plt.rcParams['font.family'] = 'Helvetica'\n",
    "# plt.rcParams['font.size'] = 6\n",
    "# plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "fontSize = 8\n",
    "\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = fontSize\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rc('xtick', labelsize=fontSize)\n",
    "plt.rc('ytick', labelsize=fontSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload in case anything updated in these functions\n",
    "importlib.reload(classifyFunctions)\n",
    "importlib.reload(plotFunctions)\n",
    "importlib.reload(helperFunctions)\n",
    "\n",
    "color_dict = helperFunctions.create_color_dict('drug', True)\n",
    "\n",
    "# Set a random seed for reproducibility.\n",
    "np.random.seed(seed = 31415)\n",
    "\n",
    "classifyDict = dict()\n",
    "\n",
    "# Parameters for pivoting the data\n",
    "classifyDict['data'] = 'count_norm' #cell_density, count, count_norm, density_norm\n",
    "classifyDict['feature'] = 'abbreviation'\n",
    "classifyDict['label'] = 'class_SSRI' # Defined in helperFunctions.create_drugClass_dict()\n",
    "# helperFunctions.create_drugClass_dict(classifyDict)\n",
    "\n",
    "# Parameters for feature scaling and aggregation\n",
    "classifyDict['featurefilt'] = False # True, False\n",
    "classifyDict['filtType'] = 'min' # Min removes the bottom 1%, Max removes the top 99th percentile.\n",
    "classifyDict['featureAgg'] = False\n",
    "classifyDict['featureSel_linkage'] = 'average'  # 'average', 'complete', 'single', 'ward' (if euclidean)\n",
    "classifyDict['featureSel_distance'] = 'correlation' # 'correlation, 'cosine', 'euclidean'\n",
    "classifyDict['cluster_count'] = 100 # Number of clusters to generate. Not used at the moment.\n",
    "classifyDict['cluster_thres'] = 0.2 # Anything closer than this is merged into a cluster\n",
    " \n",
    "# Parameters for Preprocessing and feature selection\n",
    "classifyDict['model_featureTransform'] = True # True, False\n",
    "classifyDict['model_featureScale'] = True # True, False\n",
    "classifyDict['model_featureSel'] = 'Boruta' # 'Univar', 'mutInfo', 'RFE', 'MRMR', 'Fdr', 'Fwe_BH', 'Fwe', 'Boruta', 'None'\n",
    "classifyDict['model_featureSel_alpha'] = 0.05 # Used for Fdr, Fwe, and Fwe_BH\n",
    "\n",
    "# If Fdr/Fwe/None are not used for feature selection, the number of k feature must be preset\n",
    "classifyDict['model_featureSel_mode'] = 'modelPer' # 'gridCV', 'modelPer'\n",
    "# classifyDict['model_featureSel_k'] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "classifyDict['model_featureSel_k'] = [30]\n",
    "\n",
    "# Parameters for classification\n",
    "classifyDict['model'] = 'LogRegL2' #'LogRegL2', 'LogRegL1', 'LogRegElastic', 'svm'\n",
    "classifyDict['multiclass'] = 'multinomial' # 'ovr', 'multinomial'\n",
    "classifyDict['max_iter'] = 100\n",
    "classifyDict['CVstrat'] = 'ShuffleSplit' #'StratKFold', 'ShuffleSplit'\n",
    "\n",
    "# ParamGrid Features - in instances where gridCV is set to true, these are the parameters that will be tested.\n",
    "paramGrid = dict()\n",
    "# paramGrid['classif__l1_ratio'] = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]          # used for ElasticNet\n",
    "# paramGrid['classif__C'] = [0.001, 0.01, 0.1, 1, 10]                    # used for LogisticRegression\n",
    "paramGrid['classif__C'] = [1]                    # used for LogisticRegression\n",
    "classifyDict['pGrid'] = paramGrid\n",
    "\n",
    "classifyDict['shuffle'] = True\n",
    "classifyDict['gridCV'] = False\n",
    "\n",
    "if classifyDict['CVstrat'] == 'ShuffleSplit':\n",
    "    classifyDict['CV_count'] = 100 # Number of folds for cross-validation\n",
    "else:\n",
    "    # K fold stratified can only afford n_classes of folds\n",
    "    classifyDict['CV_count'] = 8\n",
    "\n",
    "classifyDict['test_size'] = 1/4\n",
    "classifyDict['innerFold'] = 4\n",
    "\n",
    "classifyDict['saveLoadswitch'] = True\n",
    "\n",
    "plotDict = dict()\n",
    "plotDict['shapForcePlotCount'] = 20\n",
    "plotDict['shapSummaryThres'] = 75   # Thres of CV inclusion for a feature to be plotted. Set to None to use shapMaxDisplay instead.\n",
    "plotDict['shapMaxDisplay'] = 10     # Number of features to show in Shap Summary. Ignored if shapSummaryThres is not None.\n",
    "\n",
    "# Load Pickle\n",
    "lightsheet_data = pd.read_pickle('lightsheet_data.pkl') # lightsheet_data.pkl or lightsheet_all.pkl\n",
    "\n",
    "heatmapDict = dict()\n",
    "heatmapDict['data'] = 'count_norm' #cell_density, count, count_norm, density_norm\n",
    "heatmapDict['feature'] = 'abbreviation'\n",
    "heatmapDict['blockCount'] = 2\n",
    "heatmapDict['logChangeSal'] = True\n",
    "heatmapDict['areaBlocks'] = True\n",
    "heatmapDict['areaPerBlock'] = 4\n",
    "heatmapDict['SortList'] = ['PSI', 'KET', '5MEO', '6-F-DET', 'MDMA', 'A-SSRI', 'C-SSRI', 'SAL']\n",
    "\n",
    "# plotFunctions.plot_data_heatmap(lightsheet_data, heatmapDict, dirDict)\n",
    "\n",
    "# plotFunctions.distance_matrix(lightsheet_data, classifyDict, dirDict)\n",
    "\n",
    "# classifyDict['data'] = 'cell_density' #cell_density, count, count_norm, density_norm, count_norm_scaled\n",
    "# classifyFunctions.classifySamples(lightsheet_data, classifyDict, plotDict, dirDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyVec = ['class_PsiDMT', 'class_5HT2A', 'class_5HTR', 'class_PsiMDMA', 'class_SSRI', 'class_PsiDF', 'class_PsiSSRI', 'class_PsiKet', 'class_DT']\n",
    "# classifyVec = ['class_PsiDMT', 'class_PsiMDMA', 'class_PsiSSRI', 'class_PsiKet']\n",
    "\n",
    "for i in classifyVec:\n",
    "    try:\n",
    "        print(f\"Classifying {i}\")\n",
    "        classifyDict['label'] = i\n",
    "        classifyFunctions.classifySamples(lightsheet_data, classifyDict, plotDict, dirDict)\n",
    "    except Exception:\n",
    "      print(f\"\\n Failed to classify {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cFosV1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
